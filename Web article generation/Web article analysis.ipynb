{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e46c2f",
   "metadata": {},
   "source": [
    "# Web article analysis with GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to install theses libray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai --upgrade\n",
    "#%pip install dotenv in local development\n",
    "%pip install datetime\n",
    "%pip install langchain\n",
    "%pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ed10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dotenv,os # for loading environment variables in local development\n",
    "#from dotenv import load_dotenv # for loading environment variables in local development\n",
    "import datetime, openai\n",
    "from langchain_community.document_loaders.web_base import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local key \n",
    "# Import Key and Base from .env\n",
    "# load_dotenv(\"secrets.env\") \n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.organization = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "# param for results more deterministic ( 0 ) to creative (1) you could have step for experimentation like 0.5 step of 0.1 \n",
    "temperature = 0\n",
    "\n",
    "from google.colab import userdata\n",
    "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
    "# openai.organization = userdata.get('OPENAI_ORGANIZATION')\n",
    "\n",
    "# Verify if load dotenvi correct\n",
    "# print(\"OpenAI API organization : \" + openai.organization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf083314",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a4b5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4\" # you can change the model here with gpt-4 /gpt-4-32k / gpt-3.5-turbo / gpt-3.5-turbo-16k\n",
    "\n",
    "# Create the client with params for OpenAI API\n",
    "\n",
    "ClientOpenAi = openai.OpenAI(\n",
    "        api_key= openai.api_key,\n",
    "        organization= openai.organization\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2dd2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askgpt4(question, usetext=True):\n",
    "    \"\"\"\n",
    "    Ask with Open AI GPT4 model\n",
    "    \"\"\"\n",
    "    if usetext:\n",
    "        prompt = question + \"\\n\" + text\n",
    "\n",
    "    else:\n",
    "        prompt = question\n",
    "\n",
    "    response = ClientOpenAi.chat.completions.create(\n",
    "        model=model,\n",
    "        n=1,\n",
    "        temperature=temperature, # 0 to 1 by  step of 0.1 - O for  deterministic result, 1 is very creative\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8838d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea71f081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an artificial intelligence assistant designed to help answer questions, provide information, and assist with various tasks.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askgpt4(\"Who are you?\", usetext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "087808bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://medium.com/microsoftazure/introducing-langchain-agents-e58674b1a657\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e18277e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "text = \" \".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b00d05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article introduces LangChain Agents, a concept that aims to overcome the limitations of Large Language Models (LLMs) like GPT-3.5-turbo and GPT-4. These models are limited by the knowledge they have been trained on and any additional context provided. To address this, Agents are introduced as applications powered by LLMs and integrated with tools like search engines, databases, and websites. The LLM within an agent acts as a reasoning engine that plans and executes actions based on user input. The article also introduces a new prompt engineering technique called ReAct (Reason and Act). The author then discusses the implementation of an Agent powered by Azure OpenAI chat models using LangChain, a lightweight SDK. Two types of Agents are discussed: Action Agent and Plan and Execute Agent, each with different prompt engineering techniques.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"Can you summarize this article?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5ac4b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author of the article \"Introducing LangChain Agents. An implementation with Azure OpenAI and‚Ä¶\" is Valentina Alto.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"Who is the author of this article?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49ee9cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Exciting news! üéâ We're introducing LangChain Agents, a powerful implementation with Azure OpenAI and Python. üêçüíª Dive into the world of Large Language Models and discover how they're transforming the tech landscape. üåêüöÄ #AI #OpenAI #Python #TechNews\"\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"Can you write a Tweeter post with some emojis?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e86236d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text provided contains 1938 words.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"How many words in this article? Just display the result.\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31e238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI, LangChain Agents, ChatGPT, GPT-3.5-turbo, GPT-4, LangChain SDK, Language Models, Machine Learning, AI, Python, Data Science.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"Generate some keywords to classify this article?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99df4a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article belongs to the category of GENERATIVE AI as it discusses the concept of Large Language Models (LLMs) like GPT-3.5-turbo and GPT-4, their limitations, and introduces the concept of Agents which can be seen as applications powered by LLMs and integrated with a set of tools for enhanced functionality.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\n",
    "    \"Could you classify this article between GENERATIVE AI, ORACLE, GIS, TYPESCRIPT?\"\n",
    ")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90395df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The programming language used for OpenAI GPT-3 is Python.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"What is the programming language used?\")\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
