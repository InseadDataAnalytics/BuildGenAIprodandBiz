{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e46c2f",
   "metadata": {},
   "source": [
    "# Web article analysis with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.25.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (0.18.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\olmertens\\appdata\\roaming\\python\\python311\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'dotenv,'\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --upgrade\n",
    "%pip install dotenv\n",
    "%pip install datetime\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb98f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"secrets.env\")\n",
    "\n",
    "# Import Key and Base from .env\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\") #not relevant with the new library\n",
    "openai.organization = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "print(\"OpenAI API Key: \" + openai.api_organization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b463bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is: 12-Oct-2023 14:42:47\n"
     ]
    }
   ],
   "source": [
    "print(\"Today is:\", datetime.datetime.today().strftime(\"%d-%b-%Y %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd263bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.10 (main, Mar 21 2023, 18:45:11) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf083314",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4b5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4-32k\" # you can change the model here with gpt-4 /gpt-4-32k / gpt-3.5-turbo / gpt-3.5-turbo-16k\n",
    "\n",
    "# Create the client with params for OpenAI API\n",
    "\n",
    "ClientOpenAi = openai.OpenAI(\n",
    "        api_key= openai.api_key,\n",
    "        organization= openai.organization\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2dd2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askgpt4(question, usetext=True):\n",
    "    \"\"\"\n",
    "    Ask with Open AI GPT4 model\n",
    "    \"\"\"\n",
    "    if usetext:\n",
    "        prompt = question + \"\\n\" + text\n",
    "\n",
    "    else:\n",
    "        prompt = question\n",
    "\n",
    "    response = ClientOpenAi.chat.completions.create(\n",
    "        model=model,\n",
    "        n=1,\n",
    "        temperature=0, # 0 to 1 by  step of 0.1 - O for  deterministic result, 1 is very creative\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8838d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea71f081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an artificial intelligence assistant designed to help answer your questions, provide information, and assist with various tasks.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askgpt4(\"Who are you?\", usetext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087808bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://medium.com/microsoftazure/introducing-langchain-agents-e58674b1a657\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18277e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "text = \" \".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b00d05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article introduces LangChain Agents, which are systems powered by Large Language Models (LLMs) integrated with a set of tools like search engines, databases, websites, etc. These agents plan and execute actions based on user input to fulfill the request. This concept is critical because current LLMs, like GPT-3.5-turbo and GPT-4, are limited to knowledge they've been trained on and cannot obtain information from other sources. Two main types of LangChain Agents include Action Agents, which decide an action and execute it step-by-step, and Plan and Execute Agents, which use more sophisticated approach for complex tasks. The article further details how to go about implementing these agents with Azure OpenAI and Python using LangChain, a lightweight SDK that makes it easier to manage and integrate LLMs into applications.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"Can you summarize this article?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ac4b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author of the article \"Introducing LangChain Agents. An implementation with Azure OpenAI andâ€¦\" is Valentina Alto.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"Who is the author of this article?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49ee9cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Exploring the power of AI with LangChain and Azure OpenAI. Generative models will revolutionize the way we interact with data. Join the journey! ðŸš€ #AI #OpenAI #DataScience #Innovation #LangChain\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"Can you write a Tweeter post with some emojis?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e86236d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text provided contains 1938 words.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"How many words in this article? Just display the result.\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31e238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI, LangChain Agents, ChatGPT, GPT-3.5-turbo, GPT-4, LangChain SDK, Language Models, Machine Learning, AI, Python, Data Science.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"Generate some keywords to classify this article?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99df4a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article belongs to the category of GENERATIVE AI as it discusses the concept of Large Language Models (LLMs) like GPT-3.5-turbo and GPT-4, their limitations, and introduces the concept of Agents which can be seen as applications powered by LLMs and integrated with a set of tools for enhanced functionality.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\n",
    "    \"Could you classify this article between GENERATIVE AI, ORACLE, GIS, TYPESCRIPT?\"\n",
    ")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90395df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The programming language used for OpenAI GPT-3 is Python.\n"
     ]
    }
   ],
   "source": [
    "answer = askgpt4(\"What is the programming language used?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2f7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
